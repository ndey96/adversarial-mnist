{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.contrib.slim as slim\n",
    "import tensorflow.contrib.slim.nets as nets\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.logging.set_verbosity(tf.logging.INFO)\n",
    "sess = tf.InteractiveSession()\n",
    "image = tf.Variable(tf.zeros((64,64)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST-data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST-data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST-data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST-data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "# Load MNIST dataset\n",
    "mnist = tf.contrib.learn.datasets.load_dataset(\"mnist\")\n",
    "train_data = mnist.train.images  # Returns np.array\n",
    "train_labels = np.asarray(mnist.train.labels, dtype=np.int32)\n",
    "test_data = mnist.test.images  # Returns np.array\n",
    "test_labels = np.asarray(mnist.test.labels, dtype=np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn_model_fn(features, labels, mode):\n",
    "  # Input Layer\n",
    "  # Reshape X to 4-D tensor: [batch_size, width, height, channels]\n",
    "  # MNIST images are 28x28 pixels, and have one color channel\n",
    "  input_layer = tf.reshape(features[\"x\"], [-1, 28, 28, 1])\n",
    "\n",
    "  # Convolutional Layer #1\n",
    "  # Computes 32 features using a 5x5 filter with ReLU activation.\n",
    "  # Padding is added to preserve width and height.\n",
    "  # Input Tensor Shape: [batch_size, 28, 28, 1]\n",
    "  # Output Tensor Shape: [batch_size, 28, 28, 32]\n",
    "  conv1 = tf.layers.conv2d(\n",
    "      inputs=input_layer,\n",
    "      filters=32,\n",
    "      kernel_size=[5, 5],\n",
    "      padding=\"same\",\n",
    "      activation=tf.nn.relu)\n",
    "\n",
    "  # Pooling Layer #1\n",
    "  # First max pooling layer with a 2x2 filter and stride of 2\n",
    "  # Input Tensor Shape: [batch_size, 28, 28, 32]\n",
    "  # Output Tensor Shape: [batch_size, 14, 14, 32]\n",
    "  pool1 = tf.layers.max_pooling2d(inputs=conv1, pool_size=[2, 2], strides=2)\n",
    "\n",
    "  # Convolutional Layer #2\n",
    "  # Computes 64 features using a 5x5 filter.\n",
    "  # Padding is added to preserve width and height.\n",
    "  # Input Tensor Shape: [batch_size, 14, 14, 32]\n",
    "  # Output Tensor Shape: [batch_size, 14, 14, 64]\n",
    "  conv2 = tf.layers.conv2d(\n",
    "      inputs=pool1,\n",
    "      filters=64,\n",
    "      kernel_size=[5, 5],\n",
    "      padding=\"same\",\n",
    "      activation=tf.nn.relu)\n",
    "\n",
    "  # Pooling Layer #2\n",
    "  # Second max pooling layer with a 2x2 filter and stride of 2\n",
    "  # Input Tensor Shape: [batch_size, 14, 14, 64]\n",
    "  # Output Tensor Shape: [batch_size, 7, 7, 64]\n",
    "  pool2 = tf.layers.max_pooling2d(inputs=conv2, pool_size=[2, 2], strides=2)\n",
    "\n",
    "  # Flatten tensor into a batch of vectors\n",
    "  # Input Tensor Shape: [batch_size, 7, 7, 64]\n",
    "  # Output Tensor Shape: [batch_size, 7 * 7 * 64]\n",
    "  pool2_flat = tf.reshape(pool2, [-1, 7 * 7 * 64])\n",
    "\n",
    "  # Dense Layer\n",
    "  # Densely connected layer with 1024 neurons\n",
    "  # Input Tensor Shape: [batch_size, 7 * 7 * 64]\n",
    "  # Output Tensor Shape: [batch_size, 1024]\n",
    "  dense = tf.layers.dense(inputs=pool2_flat, units=1024, activation=tf.nn.relu)\n",
    "\n",
    "  # Add dropout operation; 0.6 probability that element will be kept\n",
    "  dropout = tf.layers.dropout(\n",
    "      inputs=dense, rate=0.4, training=mode == tf.estimator.ModeKeys.TRAIN)\n",
    "\n",
    "  # Logits layer\n",
    "  # Input Tensor Shape: [batch_size, 1024]\n",
    "  # Output Tensor Shape: [batch_size, 10]\n",
    "  logits = tf.layers.dense(inputs=dropout, units=10)\n",
    "\n",
    "  predictions = {\n",
    "      # Generate predictions (for PREDICT and EVAL mode)\n",
    "      \"classes\": tf.argmax(input=logits, axis=1),\n",
    "      # Add `softmax_tensor` to the graph. It is used for PREDICT and by the\n",
    "      # `logging_hook`.\n",
    "      \"probabilities\": tf.nn.softmax(logits, name=\"softmax_tensor\")\n",
    "  }\n",
    "  if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "    return tf.estimator.EstimatorSpec(mode=mode, predictions=predictions)\n",
    "\n",
    "  # Calculate Loss (for both TRAIN and EVAL modes)\n",
    "  loss = tf.losses.sparse_softmax_cross_entropy(labels=labels, logits=logits)\n",
    "\n",
    "  # Configure the Training Op (for TRAIN mode)\n",
    "  if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.001)\n",
    "    train_op = optimizer.minimize(\n",
    "        loss=loss,\n",
    "        global_step=tf.train.get_global_step())\n",
    "    return tf.estimator.EstimatorSpec(mode=mode, loss=loss, train_op=train_op)\n",
    "\n",
    "  # Add evaluation metrics (for EVAL mode)\n",
    "  eval_metric_ops = {\n",
    "      \"accuracy\": tf.metrics.accuracy(\n",
    "          labels=labels, predictions=predictions[\"classes\"])}\n",
    "  return tf.estimator.EstimatorSpec(\n",
    "      mode=mode, loss=loss, eval_metric_ops=eval_metric_ops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST-data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST-data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST-data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST-data/t10k-labels-idx1-ubyte.gz\n",
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_task_type': 'worker', '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x11a4b9f90>, '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_num_ps_replicas': 0, '_tf_random_seed': None, '_master': '', '_num_worker_replicas': 1, '_task_id': 0, '_log_step_count_steps': 100, '_model_dir': 'mnist_convnet_model', '_save_summary_steps': 100}\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from mnist_convnet_model/model.ckpt-20105\n",
      "INFO:tensorflow:Saving checkpoints for 20106 into mnist_convnet_model/model.ckpt.\n",
      "INFO:tensorflow:probabilities = [[0.00000885 0.00000644 0.00248517 0.00068558 0.00000057 0.00000033\n",
      "  0.         0.98429537 0.00006601 0.01245163]\n",
      " [0.00001838 0.00000334 0.0001574  0.00002405 0.99436826 0.00004576\n",
      "  0.0004429  0.00057859 0.00004785 0.00431348]\n",
      " [0.00010848 0.00002382 0.00350951 0.01135447 0.00000158 0.00601779\n",
      "  0.00064248 0.00000226 0.9783337  0.00000597]\n",
      " [0.00014191 0.00026446 0.00102677 0.9783659  0.0000026  0.0199743\n",
      "  0.00000042 0.00002026 0.00003426 0.00016918]\n",
      " [0.00000752 0.0000024  0.00015145 0.00012147 0.00000145 0.00000191\n",
      "  0.         0.99908626 0.0005529  0.00007464]\n",
      " [0.00000474 0.99801314 0.00013499 0.00016421 0.00103643 0.00001616\n",
      "  0.00003642 0.00008731 0.00046364 0.00004296]\n",
      " [0.99959046 0.00000021 0.00000258 0.00010005 0.         0.00027931\n",
      "  0.00000499 0.00001059 0.0000041  0.00000766]\n",
      " [0.00056755 0.00182691 0.00004719 0.02374954 0.00303114 0.9563887\n",
      "  0.00043518 0.00350343 0.00792145 0.00252893]\n",
      " [0.00032234 0.01488956 0.01816258 0.8632936  0.00223722 0.04019786\n",
      "  0.00047862 0.00009606 0.05973859 0.00058379]\n",
      " [0.00289717 0.00041438 0.8148011  0.04418816 0.00348625 0.00038712\n",
      "  0.00102381 0.12308786 0.0006405  0.00907365]\n",
      " [0.00002354 0.00000003 0.00002833 0.00006615 0.00000316 0.00035168\n",
      "  0.00000016 0.00011428 0.9970722  0.00234043]\n",
      " [0.00057462 0.00000491 0.00028038 0.00126524 0.00301859 0.0011154\n",
      "  0.00002309 0.00443284 0.00030011 0.9889847 ]\n",
      " [0.00000066 0.00000003 0.00008732 0.0000002  0.9997813  0.00000012\n",
      "  0.00002286 0.00004712 0.00000005 0.0000604 ]\n",
      " [0.00001408 0.0000025  0.00004263 0.00099822 0.00000339 0.9939592\n",
      "  0.00000348 0.00000303 0.00480162 0.0001718 ]\n",
      " [0.00009434 0.00000047 0.00013878 0.00002994 0.8716403  0.00014337\n",
      "  0.00010571 0.00060585 0.00437771 0.12286349]\n",
      " [0.00065022 0.00005398 0.9259772  0.01448312 0.00000026 0.0000051\n",
      "  0.00000068 0.0059379  0.0525596  0.00033193]\n",
      " [0.00001244 0.00000253 0.00002116 0.0000043  0.00017577 0.00016259\n",
      "  0.9996182  0.00000017 0.00000204 0.00000086]\n",
      " [0.00022509 0.00000062 0.00000206 0.00090463 0.00011895 0.974256\n",
      "  0.00000391 0.00005889 0.00211762 0.02231228]\n",
      " [0.00004936 0.00087193 0.00088653 0.0010074  0.01816534 0.00899582\n",
      "  0.96971387 0.00000484 0.00030128 0.00000356]\n",
      " [0.00000212 0.99656135 0.00009581 0.00167846 0.00041869 0.00003671\n",
      "  0.00006607 0.00009207 0.00097461 0.00007404]\n",
      " [0.00000223 0.0000771  0.00062338 0.99586415 0.00000452 0.00198659\n",
      "  0.00000055 0.00000258 0.00113225 0.00030672]\n",
      " [0.00002075 0.00035425 0.9977944  0.00176237 0.00000001 0.00000229\n",
      "  0.00000042 0.00000054 0.00006465 0.00000014]\n",
      " [0.00225645 0.00259271 0.00545848 0.8714509  0.00000365 0.00292146\n",
      "  0.00000012 0.09695275 0.00359648 0.01476696]\n",
      " [0.00022632 0.00000024 0.00419138 0.00004727 0.00001844 0.00000899\n",
      "  0.9953734  0.00000597 0.00012781 0.00000028]\n",
      " [0.00013294 0.99031854 0.00038048 0.0024117  0.00113049 0.00055324\n",
      "  0.00023507 0.00140211 0.00173791 0.00169764]\n",
      " [0.00007325 0.00017506 0.00946958 0.94358367 0.00533889 0.00548661\n",
      "  0.00001951 0.00035854 0.02021746 0.01527754]\n",
      " [0.00476224 0.01714483 0.5270714  0.12370573 0.00045136 0.01376732\n",
      "  0.312974   0.00000771 0.00011449 0.00000087]\n",
      " [0.9969584  0.00000013 0.00065971 0.00014989 0.00000057 0.00047841\n",
      "  0.00000549 0.00009231 0.00001472 0.00164046]\n",
      " [0.00392758 0.00012585 0.00114755 0.00001991 0.0002513  0.00780337\n",
      "  0.98177147 0.0000066  0.00488809 0.00005828]\n",
      " [0.00223589 0.00000845 0.00226459 0.00031982 0.03061828 0.00003825\n",
      "  0.0000596  0.11238477 0.00320901 0.84886134]\n",
      " [0.00168801 0.000007   0.00011199 0.00001561 0.00139769 0.00042191\n",
      "  0.99538124 0.00000253 0.00095425 0.00001987]\n",
      " [0.99983096 0.00000041 0.00013046 0.00000345 0.00000127 0.00000511\n",
      "  0.00000611 0.00001025 0.00000415 0.00000776]\n",
      " [0.00011706 0.00000642 0.0001314  0.15859061 0.00010432 0.8030729\n",
      "  0.00004476 0.00005482 0.03406812 0.00380948]\n",
      " [0.00000001 0.         0.00000026 0.00000059 0.00000059 0.0000074\n",
      "  0.         0.9999099  0.00000009 0.00008121]\n",
      " [0.00000004 0.00000128 0.00013385 0.9688945  0.00000009 0.00003267\n",
      "  0.         0.00000224 0.0309009  0.00003445]\n",
      " [0.00026124 0.00000058 0.00000072 0.00000461 0.00022075 0.00288841\n",
      "  0.00000065 0.98133105 0.00001605 0.01527597]\n",
      " [0.0007357  0.00032804 0.04443778 0.00131873 0.00022628 0.00485503\n",
      "  0.00012907 0.94064933 0.00034116 0.00697892]\n",
      " [0.00025366 0.00164102 0.17376074 0.06538815 0.0000623  0.00024532\n",
      "  0.00000287 0.7580057  0.00007367 0.00056646]\n",
      " [0.9999597  0.         0.0000005  0.         0.         0.00003929\n",
      "  0.00000041 0.00000001 0.         0.00000003]\n",
      " [0.00000068 0.00003506 0.00000448 0.00005964 0.9908908  0.00036846\n",
      "  0.00009237 0.00009453 0.00132184 0.00713214]\n",
      " [0.00000041 0.00000253 0.0000007  0.00017112 0.00445669 0.00012261\n",
      "  0.00000022 0.00010772 0.00104349 0.99409455]\n",
      " [0.00000556 0.000028   0.00001055 0.0003583  0.00035416 0.98774475\n",
      "  0.00029776 0.00001349 0.00787759 0.00330989]\n",
      " [0.00075057 0.00000193 0.00002062 0.03356819 0.00005596 0.95571625\n",
      "  0.00000336 0.00004695 0.0001033  0.00973287]\n",
      " [0.00053762 0.00018673 0.00112616 0.00021966 0.08137721 0.00131497\n",
      "  0.00069893 0.0099594  0.01120931 0.89337   ]\n",
      " [0.00001651 0.99288815 0.00076709 0.00095738 0.00015774 0.00000119\n",
      "  0.000024   0.0022818  0.00273067 0.00017542]\n",
      " [0.00000056 0.00012993 0.00199533 0.99579716 0.00000513 0.0000172\n",
      "  0.00000007 0.00014854 0.00183588 0.00007032]\n",
      " [0.00000356 0.00000383 0.00062089 0.99547845 0.00000066 0.00008341\n",
      "  0.00000001 0.00000463 0.0036713  0.00013333]\n",
      " [0.00034474 0.00002989 0.0003818  0.00019351 0.20531543 0.00029187\n",
      "  0.00085548 0.00132515 0.00297833 0.7882838 ]\n",
      " [0.00000156 0.99583924 0.00058633 0.00055503 0.00010361 0.00002261\n",
      "  0.00010968 0.00004774 0.00270281 0.00003153]\n",
      " [0.00000067 0.9958508  0.000114   0.00017214 0.00000426 0.00007782\n",
      "  0.00036336 0.00000533 0.00341082 0.00000063]\n",
      " [0.01133394 0.00458403 0.8980909  0.00858293 0.00034813 0.0033974\n",
      "  0.00104383 0.00146219 0.06907582 0.00208081]\n",
      " [0.02159285 0.0025092  0.03138824 0.00005527 0.00135639 0.684235\n",
      "  0.2551713  0.00000959 0.0034369  0.00024527]\n",
      " [0.00000266 0.00000025 0.00000593 0.0000048  0.9600877  0.00175258\n",
      "  0.00008178 0.00002019 0.00314521 0.034899  ]\n",
      " [0.00024607 0.0000009  0.00003612 0.00000032 0.000159   0.00420847\n",
      "  0.994846   0.         0.00050188 0.00000116]\n",
      " [0.00001447 0.00002347 0.00061371 0.00015815 0.00000117 0.00000208\n",
      "  0.00000001 0.9975418  0.00001473 0.00163044]\n",
      " [0.9933623  0.00001503 0.00348216 0.0001439  0.00000242 0.00101162\n",
      "  0.00010982 0.00012232 0.00072306 0.00102744]\n",
      " [0.00023427 0.00000009 0.99897015 0.00017658 0.00000213 0.00000835\n",
      "  0.00000117 0.00003579 0.0005246  0.00004692]\n",
      " [0.00005491 0.00003957 0.00003494 0.01735488 0.00001834 0.98082614\n",
      "  0.00007611 0.00000526 0.00073499 0.0008549 ]\n",
      " [0.00006586 0.00003143 0.00058804 0.00390597 0.00001277 0.00012258\n",
      "  0.00000217 0.00002752 0.9883767  0.00686704]\n",
      " [0.0004292  0.0000005  0.00197955 0.00011096 0.00245006 0.00021903\n",
      "  0.00001503 0.00465617 0.00006848 0.990071  ]\n",
      " [0.00094668 0.0000009  0.00111473 0.00001134 0.00015449 0.00005285\n",
      "  0.9977182  0.00000002 0.0000007  0.00000019]\n",
      " [0.00007327 0.00064048 0.99082196 0.00213685 0.00062901 0.00000319\n",
      "  0.00284785 0.0000176  0.00281476 0.00001487]\n",
      " [0.00000417 0.00000071 0.00000275 0.00090341 0.00721014 0.00003316\n",
      "  0.00000086 0.046763   0.00029502 0.9447868 ]\n",
      " [0.00000296 0.00000096 0.00001963 0.00000078 0.99941945 0.00001331\n",
      "  0.00011902 0.0000606  0.00019605 0.00016725]\n",
      " [0.629513   0.00000025 0.00031632 0.00004424 0.00028248 0.00610314\n",
      "  0.00025483 0.00028735 0.00221911 0.36097923]\n",
      " [0.00000795 0.00001258 0.00023029 0.00027975 0.03253977 0.00012307\n",
      "  0.00000251 0.00241127 0.00011904 0.96427375]\n",
      " [0.00007204 0.00869029 0.00567239 0.00672512 0.00004178 0.00024331\n",
      "  0.0000016  0.97341406 0.00032591 0.00481353]\n",
      " [0.00003463 0.01229079 0.11642433 0.7837573  0.03345039 0.00211212\n",
      "  0.00003067 0.00045702 0.04376687 0.00767584]\n",
      " [0.00027202 0.9410732  0.00682821 0.00496002 0.01759429 0.00068477\n",
      "  0.0008559  0.00091179 0.02680663 0.00001318]\n",
      " [0.00050032 0.06533068 0.00232524 0.9240328  0.00000184 0.0029934\n",
      "  0.00000057 0.00063768 0.00222549 0.00195193]\n",
      " [0.00032127 0.00000008 0.9939329  0.0041526  0.00015032 0.0000198\n",
      "  0.00028221 0.00026452 0.00084986 0.00002646]\n",
      " [0.9982652  0.00000029 0.00002284 0.00000108 0.00000211 0.00124424\n",
      "  0.00034787 0.00000631 0.00009211 0.00001791]\n",
      " [0.00000014 0.00025747 0.99506795 0.00464746 0.00000002 0.00000215\n",
      "  0.00000169 0.00000001 0.00002314 0.        ]\n",
      " [0.00000017 0.00000263 0.00053204 0.00029745 0.00033665 0.00000014\n",
      "  0.00000002 0.99812645 0.00001714 0.00068742]\n",
      " [0.00000016 0.00000005 0.00000016 0.00000061 0.9969614  0.00000638\n",
      "  0.0000003  0.00000395 0.0000335  0.00299356]\n",
      " [0.00000044 0.00000002 0.00000042 0.00009541 0.00000026 0.99735534\n",
      "  0.00000007 0.00000032 0.0025456  0.00000224]\n",
      " [0.00014784 0.00001174 0.00001622 0.7612015  0.00000123 0.03042592\n",
      "  0.00000002 0.08842534 0.00058904 0.11918106]\n",
      " [0.00000448 0.00000903 0.0000636  0.00030584 0.00734168 0.00028247\n",
      "  0.00000509 0.00102502 0.00065404 0.9903088 ]\n",
      " [0.0000034  0.98452085 0.00069944 0.00150871 0.00345079 0.00274355\n",
      "  0.00146842 0.00024885 0.00491959 0.00043649]\n",
      " [0.00417803 0.00011054 0.0002543  0.00339348 0.44303933 0.03381266\n",
      "  0.00016798 0.04831459 0.00031049 0.46641862]\n",
      " [0.9892536  0.00000904 0.00031366 0.001361   0.00000301 0.00690135\n",
      "  0.00098246 0.00029995 0.00084027 0.00003561]\n",
      " [0.00384672 0.00002892 0.00057233 0.00003578 0.00064817 0.00040732\n",
      "  0.99433917 0.00000212 0.00010132 0.00001824]\n",
      " [0.00002044 0.00000021 0.0000134  0.00362078 0.00000043 0.9954997\n",
      "  0.00001095 0.00000005 0.0007413  0.00009268]\n",
      " [0.00052744 0.00001884 0.00053811 0.00005794 0.00046907 0.00085046\n",
      "  0.99737024 0.00000719 0.00015017 0.00001064]\n",
      " [0.00548577 0.00036787 0.00863084 0.00052396 0.00762558 0.00437206\n",
      "  0.97292906 0.0000078  0.00001233 0.00004469]\n",
      " [0.00134543 0.00001486 0.02100076 0.90965337 0.00039748 0.00046175\n",
      "  0.00001084 0.00048634 0.00757203 0.05905712]\n",
      " [0.00000242 0.99353176 0.00005925 0.0003872  0.00026825 0.00004171\n",
      "  0.00070092 0.00010285 0.00489192 0.00001361]\n",
      " [0.00001339 0.00000198 0.00000239 0.00141421 0.00000053 0.9959578\n",
      "  0.00001423 0.00000005 0.00252949 0.00006587]\n",
      " [0.00001065 0.00001109 0.9992679  0.00017158 0.00005398 0.00000105\n",
      "  0.00009991 0.000261   0.00011264 0.00001021]\n",
      " [0.00000121 0.99914694 0.00000792 0.00022504 0.00009537 0.00000418\n",
      "  0.0000141  0.00006699 0.00042305 0.00001519]\n",
      " [0.0000032  0.0000043  0.00007401 0.0005521  0.00051613 0.00032563\n",
      "  0.00000024 0.0009215  0.4931702  0.50443274]\n",
      " [0.00000437 0.00000067 0.00033068 0.00038587 0.00000001 0.00000081\n",
      "  0.         0.9990693  0.00002159 0.00018681]\n",
      " [0.00001477 0.00000011 0.00001705 0.0000002  0.00011127 0.00030888\n",
      "  0.9995067  0.         0.00004035 0.00000059]\n",
      " [0.00126001 0.00001669 0.00056367 0.00011899 0.0012541  0.00063551\n",
      "  0.9961357  0.00000267 0.00001078 0.00000179]\n",
      " [0.0000075  0.00001429 0.00001932 0.00008045 0.68374383 0.00341914\n",
      "  0.00000694 0.00098018 0.00086481 0.31086364]\n",
      " [0.00018253 0.00000041 0.00001212 0.00023685 0.00000046 0.9991573\n",
      "  0.00000045 0.00000171 0.00010638 0.00030186]\n",
      " [0.00000141 0.00000947 0.9996942  0.00027839 0.00000184 0.00000069\n",
      "  0.00000011 0.00000511 0.00000728 0.00000157]\n",
      " [0.00009818 0.00030673 0.0052968  0.95678645 0.00016254 0.02483866\n",
      "  0.00043582 0.00005612 0.01101566 0.00100295]\n",
      " [0.0000033  0.00000016 0.94858634 0.04450955 0.         0.00000036\n",
      "  0.         0.00007558 0.00682467 0.00000002]\n",
      " [0.00162555 0.00994399 0.01443996 0.01924558 0.04533173 0.80656135\n",
      "  0.00839396 0.06126896 0.01507319 0.01811586]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.08612261, step = 20106\n",
      "INFO:tensorflow:probabilities = [[0.00026275 0.00002539 0.00023357 0.00049541 0.72091204 0.00038605\n",
      "  0.00090254 0.00107079 0.00113476 0.27457675]\n",
      " [0.99999857 0.         0.00000095 0.00000001 0.         0.00000002\n",
      "  0.00000007 0.00000002 0.00000003 0.00000033]\n",
      " [0.00000811 0.00000228 0.00003931 0.00196709 0.00000086 0.00473626\n",
      "  0.00000774 0.00000113 0.9931577  0.00007959]\n",
      " [0.00125632 0.00024332 0.97536474 0.0140824  0.00016618 0.00040977\n",
      "  0.00000257 0.00082532 0.00568732 0.0019621 ]\n",
      " [0.00034216 0.00000097 0.00000752 0.00007543 0.00014324 0.00018742\n",
      "  0.00000004 0.9719063  0.00003174 0.02730514]\n",
      " [0.00004216 0.99690443 0.00037796 0.00047982 0.00015632 0.00001111\n",
      "  0.00021134 0.00044835 0.00133802 0.00003041]\n",
      " [0.00075771 0.00000029 0.00014759 0.00005405 0.00007247 0.00003972\n",
      "  0.9982975  0.00000049 0.00062923 0.00000107]\n",
      " [0.00016829 0.00000598 0.00033938 0.00002425 0.00005203 0.00000704\n",
      "  0.99907684 0.00002815 0.0002968  0.00000116]\n",
      " [0.8044185  0.000022   0.00712507 0.00049789 0.01287472 0.00509834\n",
      "  0.00498058 0.09121951 0.00051195 0.07325141]\n",
      " [0.00000578 0.00025052 0.00101784 0.9951125  0.00015692 0.00293216\n",
      "  0.00001132 0.00029962 0.00016957 0.00004385]\n",
      " [0.00012647 0.00088989 0.00099795 0.00133731 0.00269552 0.00018101\n",
      "  0.00001386 0.00749048 0.00094094 0.9853265 ]\n",
      " [0.00159617 0.00000916 0.08415823 0.00098885 0.00156403 0.00289524\n",
      "  0.00299838 0.00000045 0.90471685 0.00107258]\n",
      " [0.00013595 0.00002792 0.00034419 0.00849599 0.02362882 0.00030627\n",
      "  0.0000354  0.01466104 0.00025187 0.9521126 ]\n",
      " [0.00003177 0.00861521 0.570689   0.41926908 0.00000032 0.00071906\n",
      "  0.00000593 0.00020261 0.00046537 0.00000154]\n",
      " [0.00000003 0.         0.00000003 0.00000004 0.00000182 0.00000177\n",
      "  0.         0.999961   0.00000004 0.00003525]\n",
      " [0.00000205 0.0000093  0.00021026 0.00100635 0.00678427 0.00000938\n",
      "  0.00000029 0.00313999 0.00033575 0.9885024 ]\n",
      " [0.00065764 0.00011388 0.00280183 0.00001357 0.00200089 0.00010477\n",
      "  0.99426866 0.00000295 0.00003489 0.00000089]\n",
      " [0.00002436 0.00000356 0.00032132 0.00029121 0.00047316 0.00000864\n",
      "  0.00000021 0.04548388 0.00226318 0.9511305 ]\n",
      " [0.00000481 0.         0.9999434  0.00000443 0.00000684 0.00000113\n",
      "  0.00000373 0.00000003 0.00003547 0.00000014]\n",
      " [0.00001669 0.00000077 0.00001596 0.00000609 0.9927914  0.00041186\n",
      "  0.00022675 0.00014873 0.00108292 0.00529879]\n",
      " [0.00000162 0.00000094 0.00001063 0.00000118 0.99971205 0.00000109\n",
      "  0.00007974 0.0000123  0.00004165 0.00013881]\n",
      " [0.00000101 0.00000009 0.00000186 0.00000019 0.99987483 0.00000145\n",
      "  0.00000897 0.00003164 0.00000341 0.00007662]\n",
      " [0.0000978  0.00004715 0.7774069  0.02326113 0.00019502 0.00150537\n",
      "  0.00000199 0.00667057 0.11570891 0.07510521]\n",
      " [0.00085643 0.00440384 0.77251905 0.00434898 0.01360684 0.0005016\n",
      "  0.02608582 0.00001187 0.1775779  0.00008779]\n",
      " [0.0000544  0.9949846  0.00059232 0.00070748 0.00099222 0.00019339\n",
      "  0.0001039  0.00067856 0.00155665 0.00013645]\n",
      " [0.00013464 0.9836481  0.00092718 0.00134221 0.0018381  0.00104258\n",
      "  0.00224077 0.00480809 0.00278441 0.00123397]\n",
      " [0.00003424 0.00211219 0.00047715 0.00413676 0.00049136 0.9844273\n",
      "  0.00035955 0.00007614 0.00778238 0.0001029 ]\n",
      " [0.00000838 0.00006312 0.00093476 0.00009393 0.00009415 0.00003399\n",
      "  0.00113299 0.0000005  0.9975325  0.00010566]\n",
      " [0.00000673 0.00060103 0.9960561  0.00245473 0.00006275 0.00014623\n",
      "  0.00055993 0.00005196 0.00005403 0.00000652]\n",
      " [0.00006969 0.00000726 0.0000318  0.00063567 0.01711178 0.00026315\n",
      "  0.00000728 0.00365132 0.00036501 0.977857  ]\n",
      " [0.00067183 0.00002936 0.00034017 0.00005899 0.00196414 0.00966876\n",
      "  0.9828928  0.00000064 0.0043481  0.0000252 ]\n",
      " [0.00003285 0.9964038  0.00084677 0.00020483 0.00013058 0.00001256\n",
      "  0.00026251 0.00102852 0.00107438 0.00000314]\n",
      " [0.0077881  0.00005938 0.00183798 0.00030482 0.02362955 0.0107776\n",
      "  0.91485727 0.00000145 0.03825612 0.00248773]\n",
      " [0.00015015 0.00016499 0.00173316 0.05999861 0.00027758 0.00113414\n",
      "  0.00000567 0.00090574 0.7325451  0.20308489]\n",
      " [0.00005742 0.00004349 0.00565505 0.00011364 0.00004949 0.00008675\n",
      "  0.00027461 0.00013558 0.99297136 0.00061268]\n",
      " [0.00007268 0.00018327 0.00041134 0.00000578 0.00037389 0.00025747\n",
      "  0.99852896 0.00000481 0.00016    0.00000166]\n",
      " [0.00000942 0.9964709  0.0003763  0.00003706 0.00023128 0.00001068\n",
      "  0.00025223 0.00048932 0.00208732 0.00003554]\n",
      " [0.9961302  0.00000128 0.00008403 0.00001279 0.00000358 0.00278015\n",
      "  0.00004825 0.00037281 0.00052238 0.00004455]\n",
      " [0.0000062  0.00000288 0.00013577 0.99616396 0.00000095 0.00210512\n",
      "  0.00000001 0.00000502 0.00054575 0.00103438]\n",
      " [0.9992112  0.         0.00002949 0.00000345 0.00000004 0.00000236\n",
      "  0.00000428 0.00015937 0.0000002  0.00058963]\n",
      " [0.00000025 0.00000011 0.00000161 0.00000362 0.9996679  0.00003704\n",
      "  0.00000079 0.00002629 0.00011488 0.00014753]\n",
      " [0.00000017 0.00000258 0.00000535 0.00000668 0.00000275 0.0000004\n",
      "  0.         0.99838364 0.00000221 0.00159626]\n",
      " [0.00019631 0.9871115  0.00044369 0.00080437 0.00153582 0.00049181\n",
      "  0.0013403  0.00415727 0.00209015 0.00182881]\n",
      " [0.9520682  0.00031977 0.00992365 0.00392808 0.00604276 0.00020597\n",
      "  0.02487325 0.00064276 0.00092077 0.00107485]\n",
      " [0.00000996 0.00000984 0.0025654  0.99292177 0.00000747 0.00026319\n",
      "  0.00000136 0.00000113 0.00419434 0.00002548]\n",
      " [0.00002782 0.00005965 0.00009005 0.00000176 0.00000852 0.0022905\n",
      "  0.99750096 0.00000001 0.00002069 0.00000006]\n",
      " [0.00008988 0.00000032 0.00002226 0.00045788 0.00001043 0.9982383\n",
      "  0.00050424 0.000001   0.00039638 0.00027929]\n",
      " [0.00000342 0.00000051 0.01938277 0.9745472  0.00000013 0.00001238\n",
      "  0.00000001 0.00590041 0.00014695 0.0000062 ]\n",
      " [0.00000534 0.00000028 0.00002966 0.00000122 0.00152669 0.00000653\n",
      "  0.9984048  0.00000004 0.00000726 0.00001822]\n",
      " [0.9999442  0.         0.00000272 0.0000014  0.         0.00004886\n",
      "  0.00000011 0.0000023  0.00000026 0.00000014]\n",
      " [0.00000023 0.00000001 0.00000146 0.00033176 0.0000002  0.00013845\n",
      "  0.         0.00001196 0.99947375 0.00004223]\n",
      " [0.99927527 0.0000002  0.00016963 0.00006682 0.00000214 0.00000513\n",
      "  0.00000385 0.00005276 0.00002836 0.00039587]\n",
      " [0.00003666 0.00033218 0.00004683 0.00078751 0.00127974 0.00033464\n",
      "  0.00000663 0.8619468  0.00002967 0.13519922]\n",
      " [0.00000521 0.00000004 0.00000804 0.00000583 0.00043453 0.00000063\n",
      "  0.00000047 0.1071386  0.00000514 0.8924016 ]\n",
      " [0.00019409 0.00179275 0.00029572 0.03694871 0.00059592 0.92275184\n",
      "  0.00223421 0.00001257 0.03457372 0.0006004 ]\n",
      " [0.03199837 0.00114167 0.10385407 0.00067009 0.00055071 0.7272174\n",
      "  0.12587872 0.00000248 0.0085892  0.00009746]\n",
      " [0.0001089  0.00015602 0.00014039 0.00005861 0.12151394 0.00148632\n",
      "  0.00002781 0.01163021 0.0004576  0.8644202 ]\n",
      " [0.00000657 0.00000018 0.00000761 0.00003114 0.00000068 0.00000032\n",
      "  0.         0.9988323  0.00005656 0.00106469]\n",
      " [0.00000018 0.0000014  0.00001846 0.02259882 0.00181137 0.00000103\n",
      "  0.0000001  0.9586687  0.00007095 0.01682894]\n",
      " [0.00000282 0.00000072 0.9996741  0.00028072 0.0000002  0.00000022\n",
      "  0.00000847 0.         0.00003273 0.        ]\n",
      " [0.9992054  0.0000143  0.00026734 0.00010824 0.00001178 0.00006797\n",
      "  0.00020116 0.00000985 0.0001129  0.00000103]\n",
      " [0.00066251 0.00303001 0.00895255 0.05773699 0.00492569 0.01665038\n",
      "  0.00048429 0.00116302 0.6509016  0.25549293]\n",
      " [0.00000108 0.00000008 0.0000079  0.99996173 0.00000001 0.0000054\n",
      "  0.         0.         0.00001478 0.00000908]\n",
      " [0.00001412 0.99489367 0.00051857 0.00011901 0.0002641  0.00011816\n",
      "  0.00044488 0.0014966  0.00196111 0.00016992]\n",
      " [0.00002932 0.00000046 0.00440024 0.00058043 0.00000002 0.00000042\n",
      "  0.         0.9948921  0.00001848 0.00007856]\n",
      " [0.00000449 0.00000008 0.00001049 0.00003013 0.00157921 0.00001044\n",
      "  0.00000014 0.00053016 0.00009288 0.99774194]\n",
      " [0.         0.00000001 0.00890829 0.9910891  0.         0.00000066\n",
      "  0.         0.00000067 0.00000098 0.00000021]\n",
      " [0.00022732 0.00001913 0.00012901 0.0003813  0.00030933 0.00002947\n",
      "  0.00000038 0.8389629  0.00011016 0.1598309 ]\n",
      " [0.00100522 0.00000106 0.00050142 0.0000811  0.05633726 0.00184818\n",
      "  0.00001867 0.05055658 0.00256388 0.88708663]\n",
      " [0.00016221 0.980513   0.001071   0.00077719 0.00081044 0.00035105\n",
      "  0.00536448 0.00035169 0.01044094 0.00015805]\n",
      " [0.00006982 0.99762446 0.00017666 0.0004929  0.00020875 0.00005456\n",
      "  0.00050887 0.00026631 0.0005338  0.00006381]\n",
      " [0.00000259 0.00000053 0.00000376 0.7828274  0.00000619 0.0003492\n",
      "  0.00000001 0.00007414 0.00306003 0.21367618]\n",
      " [0.00150132 0.9556051  0.00449076 0.00026715 0.01870979 0.00002963\n",
      "  0.00659713 0.0010702  0.01062893 0.00110001]\n",
      " [0.00590718 0.00013658 0.00265524 0.00059288 0.8267829  0.00016235\n",
      "  0.00339863 0.04099886 0.00282792 0.11653748]\n",
      " [0.00015079 0.00074651 0.00692548 0.96900773 0.00008196 0.01124489\n",
      "  0.00002347 0.0000422  0.01141998 0.00035711]\n",
      " [0.00003032 0.00241591 0.00696876 0.15335526 0.00088855 0.00562438\n",
      "  0.00000736 0.74111557 0.01716693 0.07242701]\n",
      " [0.00001595 0.00000138 0.00005005 0.00000157 0.9995938  0.00000427\n",
      "  0.00007132 0.00002789 0.00002365 0.00021007]\n",
      " [0.00000019 0.00000646 0.00017293 0.99970895 0.00003012 0.00002032\n",
      "  0.00000007 0.00001882 0.00002872 0.00001335]\n",
      " [0.01238099 0.01274702 0.00095309 0.00041633 0.00039866 0.36900315\n",
      "  0.04590996 0.00163461 0.55611694 0.00043919]\n",
      " [0.01194981 0.00045944 0.00070763 0.00124266 0.00056605 0.00559394\n",
      "  0.97945696 0.00000042 0.00002258 0.00000042]\n",
      " [0.00000093 0.00000029 0.00004002 0.99850345 0.00000001 0.00033663\n",
      "  0.         0.0000014  0.00072816 0.0003891 ]\n",
      " [0.00000054 0.0000003  0.00000023 0.00082828 0.00000331 0.99892324\n",
      "  0.00000001 0.00000694 0.00017138 0.00006575]\n",
      " [0.00004391 0.00000128 0.00001255 0.00000744 0.00097988 0.00006808\n",
      "  0.00000341 0.00104574 0.00011289 0.99772483]\n",
      " [0.0004072  0.97656304 0.00036801 0.00078678 0.00256597 0.00014593\n",
      "  0.00031292 0.01413588 0.00283234 0.00188196]\n",
      " [0.9993507  0.00000008 0.0004551  0.00001015 0.         0.00015152\n",
      "  0.0000003  0.0000074  0.00000021 0.00002444]\n",
      " [0.00000371 0.00000284 0.00005343 0.00005323 0.00001215 0.00000073\n",
      "  0.00000002 0.9972241  0.00000749 0.00264228]\n",
      " [0.00000174 0.00000003 0.00000217 0.00000002 0.00002947 0.00002236\n",
      "  0.9999417  0.         0.00000252 0.00000002]\n",
      " [0.10605296 0.00001445 0.00836969 0.7040572  0.00000016 0.16944169\n",
      "  0.00000042 0.00024069 0.00329744 0.00852518]\n",
      " [0.00207618 0.92532045 0.01955933 0.0022452  0.00041891 0.01065804\n",
      "  0.00725573 0.00002818 0.03239369 0.0000442 ]\n",
      " [0.00017071 0.00000001 0.00000081 0.00000002 0.00000781 0.0000737\n",
      "  0.99974626 0.         0.00000061 0.00000001]\n",
      " [0.944483   0.00001354 0.00099534 0.00156629 0.00028088 0.00089295\n",
      "  0.00000853 0.04954916 0.00000307 0.00220724]\n",
      " [0.00000465 0.00000041 0.00000338 0.00000002 0.00000775 0.00008428\n",
      "  0.99989593 0.         0.00000357 0.00000001]\n",
      " [0.00007919 0.1681295  0.00042837 0.00414048 0.47490564 0.03324955\n",
      "  0.00334027 0.00517253 0.05949825 0.25105613]\n",
      " [0.9906466  0.00000007 0.00019793 0.0000329  0.00000038 0.0055053\n",
      "  0.00272033 0.00012417 0.0005127  0.00025961]\n",
      " [0.00116983 0.00047912 0.01419991 0.2168449  0.0004009  0.01684745\n",
      "  0.00002217 0.00510666 0.66842574 0.07650329]\n",
      " [0.9998105  0.00000026 0.00004102 0.00005249 0.00000562 0.00006749\n",
      "  0.00001069 0.00000893 0.00000046 0.00000249]\n",
      " [0.00000567 0.00003356 0.00009207 0.00004749 0.9994331  0.00000135\n",
      "  0.00025158 0.00001547 0.00000319 0.00011651]\n",
      " [0.0000707  0.00000633 0.00087683 0.9982482  0.00000001 0.00063558\n",
      "  0.         0.00001286 0.00001994 0.00012948]\n",
      " [0.00062073 0.00433704 0.00070908 0.0026645  0.84245884 0.0016541\n",
      "  0.14347145 0.00242924 0.00042476 0.00123023]\n",
      " [0.00003105 0.00023633 0.00001685 0.00057908 0.00195018 0.00040137\n",
      "  0.00000091 0.95897424 0.00016577 0.0376443 ]] (12.201 sec)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-45-6d9ba1d4323b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m   \u001b[0minput_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_input_fn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m   \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m   hooks=[logging_hook])\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;31m# Evaluate the model and print results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/nolandey/anaconda/envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/estimator/estimator.pyc\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, input_fn, hooks, steps, max_steps, saving_listeners)\u001b[0m\n\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m     \u001b[0msaving_listeners\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_listeners_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 314\u001b[0;31m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    315\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Loss for final step: %s.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/nolandey/anaconda/envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/estimator/estimator.pyc\u001b[0m in \u001b[0;36m_train_model\u001b[0;34m(self, input_fn, hooks, saving_listeners)\u001b[0m\n\u001b[1;32m    813\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    814\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmon_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 815\u001b[0;31m           \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmon_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mestimator_spec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mestimator_spec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    816\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    817\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/nolandey/anaconda/envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    537\u001b[0m                           \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    538\u001b[0m                           \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 539\u001b[0;31m                           run_metadata=run_metadata)\n\u001b[0m\u001b[1;32m    540\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    541\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrun_step_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/nolandey/anaconda/envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1011\u001b[0m                               \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1012\u001b[0m                               \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1013\u001b[0;31m                               run_metadata=run_metadata)\n\u001b[0m\u001b[1;32m   1014\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0m_PREEMPTION_ERRORS\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1015\u001b[0m         logging.info('An error was raised. This may be due to a preemption in '\n",
      "\u001b[0;32m/Users/nolandey/anaconda/envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1087\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1088\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1089\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1090\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_PREEMPTION_ERRORS\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1091\u001b[0m       \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/nolandey/anaconda/envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1159\u001b[0m                                   \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1160\u001b[0m                                   \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1161\u001b[0;31m                                   run_metadata=run_metadata)\n\u001b[0m\u001b[1;32m   1162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1163\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/nolandey/anaconda/envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    939\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    940\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 941\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    942\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    943\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrun_step_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraw_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_with_hooks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/nolandey/anaconda/envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    893\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 895\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    896\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/nolandey/anaconda/envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1126\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1127\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1128\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1129\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1130\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/nolandey/anaconda/envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1342\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1343\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1344\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1345\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1346\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/nolandey/anaconda/envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1348\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1349\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1350\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1351\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1352\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/nolandey/anaconda/envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1327\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1328\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1329\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1330\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1331\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Load training and eval data\n",
    "mnist = tf.contrib.learn.datasets.load_dataset(\"mnist\")\n",
    "train_data = mnist.train.images  # Returns np.array\n",
    "train_labels = np.asarray(mnist.train.labels, dtype=np.int32)\n",
    "eval_data = mnist.test.images  # Returns np.array\n",
    "eval_labels = np.asarray(mnist.test.labels, dtype=np.int32)\n",
    "\n",
    "# Create the Estimator\n",
    "mnist_classifier = tf.estimator.Estimator(\n",
    "  model_fn=cnn_model_fn, model_dir=\"mnist_convnet_model\")\n",
    "\n",
    "# Set up logging for predictions\n",
    "# Log the values in the \"Softmax\" tensor with label \"probabilities\"\n",
    "tensors_to_log = {\"probabilities\": \"softmax_tensor\"}\n",
    "logging_hook = tf.train.LoggingTensorHook(\n",
    "  tensors=tensors_to_log, every_n_iter=50)\n",
    "\n",
    "# Train the model\n",
    "train_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "  x={\"x\": train_data},\n",
    "  y=train_labels,\n",
    "  batch_size=100,\n",
    "  num_epochs=None,\n",
    "  shuffle=True)\n",
    "mnist_classifier.train(\n",
    "  input_fn=train_input_fn,\n",
    "  steps=20000,\n",
    "  hooks=[logging_hook])\n",
    "\n",
    "# Evaluate the model and print results\n",
    "eval_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "  x={\"x\": eval_data},\n",
    "  y=eval_labels,\n",
    "  num_epochs=1,\n",
    "  shuffle=False)\n",
    "eval_results = mnist_classifier.evaluate(input_fn=eval_input_fn)\n",
    "print(eval_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.10233852, 'global_step': 20105, 'accuracy': 0.9704}\n"
     ]
    }
   ],
   "source": [
    "print(eval_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'module' object has no attribute 'float'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-42-709452e35e8c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplaceholder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m28\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mx_hat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0massign_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massign\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_hat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'module' object has no attribute 'float'"
     ]
    }
   ],
   "source": [
    "x = tf.placeholder(tf.float, (28,28))\n",
    "x_hat = image\n",
    "assign_op = tf.assign(x_hat, x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
